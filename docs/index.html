<!DOCTYPE html>
<html>



<head>
    <meta charset="utf-8">
    <meta name="description"
          content="">
    <meta name="keywords" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>UniEdit</title>
  
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
  
      function gtag() {
        dataLayer.push(arguments);
      }
  
      gtag('js', new Date());
  
      gtag('config', 'G-PYVRSFMDRL');
    </script>

<!-- <style>
    table {
        border-collapse: collapse;
        width: 100%;
    }
    td, th {
        border: 1px solid black;
        padding: 8px;
    }
</style> -->

<style>
    .bordered-table {
        border-collapse: collapse;
        width: 100%;
    }
    .bordered-table td, .bordered-table th {
        border: 1px solid black;
        padding: 8px;
    }
</style>

  
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">
  
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/dut.svg">
  
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
    <!-- <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> -->
    <!-- <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  </head>

<body>
    <nav class="navbar" role="navigation" aria-label="main navigation">
        <div class="navbar-brand">
          <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
          </a>
        </div>
    </nav>
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                <h1 class="title is-1 publication-title">
                    UniEdit: A Unified Tuning-Free Framework for Video Motion and Appearance Editing
                  </h1>

                </div>
                </div>
            </div>
            </div>
        </div>
    </section>
    <div id="container"></div>


    <section class="hero teaser">
        
        <div class="container is-max-desktop">
            <h2 width="90%" class="content has-text-centered">
                <p style="text-align:left; padding-left: 0px;"><b>Friendly Reminder:</b> If the videos are loading slowly, you can download this page from our <i>supplementary materials</i> and view it locally by double-clicking the "index.html" file.</p>
              </h2>
            <div class="hero-body">
              <!-- <img src="./static/images/fig1.svg" alt="Examples edited by UniEdit." style="transform: translateX(-13.5px);"/> -->
              <video autoplay controls muted loop playsinline>
                <source src="./video/iccv_submission/fig1_demo_video_compressed.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video>
              <!-- <img src="./video/fig1_demo_video.gif" alt="Your browser does not support the image tag." loop> -->
              <h2 class="content has-text-centered">
                UniEdit supports both video <strong><span style="color: #F0A780;">motion</span></strong> editing in the time axis (i.e., from playing guitar to eating or waving) and various video <strong><span style="color: #156082;">appearance</span></strong> editing scenarios (i.e., stylization, rigid/non-rigid object replacement, background modification).
              </h2>
              <h2 class="content has-text-centered">
                <p style="text-align:left; padding-left: 0px; color: red;">We organize the project page as follows:</p><p style="text-align:left; padding-left: 0px;"><a href="#sectionA">Section A</a>: Video Editing Results with UniEdit (based on CogVideoX-2B, VideoCrafter2, and LaVie);<br><a href="#sectionB">Section B</a>: Analysis on the Proposed Components in UniEdit;<br><a href="#sectionC">Section C</a>: Impact of Hyper-parameter Selection;<br><a href="#sectionD">Section D</a>: Impact of Mask-Guided Coordination;<br><a href="#sectionE">Section E</a>: More Results and Visualization;<br><a href="#sectionF">Section F</a>: Failure Cases Visualization;<br><a href="#sectionG">Section G</a>: Comparison with State-of-the-Art Methods.</p>
              </h2>
            </div>
          </div>
      </section>

      <section>
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3" id="sectionA" style="text-align:left;">Section A: Video Editing Results with UniEdit</h2>
                    <h2 class="title is-3">UniEdit + <a href="https://github.com/THUDM/CogVideo">CogVideoX-2B</a></h2>
                <p></p>

                <table style="table-layout: fixed;">
                    <tbody>
                        <br>
                        <tr>
                            <tr>
                                <td width="100%" style="text-align:center;">
                                    <video muted autoplay="autoplay" loop="loop" width="100%" preload controls>
                                        <source src="./video/iccv_submission/ours_cogvideox_compressed.mp4" type="video/mp4">
                                    </video>
                                    <br>
                                </td>
                            <tr>
                            
                        <tr>
                    </tbody>
                </table>
                <hr style="margin-top:0px">

            </div>
        
        </div>
        </div>
        
    <br>
    </section>

    <section>
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">UniEdit + <a href="https://github.com/AILab-CVC/VideoCrafter">VideoCrafter2</a></h2>
                <p></p>
                <table style="table-layout: fixed;">
                <tbody>
                    <tr>
                        <!-- First row of videos -->
                        <td width="50%" style="text-align:center;">
                            <video width="100%" autoplay muted loop>
                                <source src="video/iccv_submission/ours_videocrafter2_compressed.mp4" type="video/mp4">
                            </video>
                            <br>
                        </td>
                    <tr>
                    
                </tbody>
                </table>
                <hr style="margin-top:0px">
            </div>
        </div>
        </div>
    <br>
    </section>


    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full-width">
                    
                    <h2 class="title is-3">UniEdit + <a href="https://github.com/Vchitect/LaVie">LaVie</a> (Appearance Editing)</h2>

                    <table style="table-layout: fixed;">
                    <tbody>
                        <tr>
                            <!-- First row of videos -->
                            <td width="100%" style="text-align:center;"> 
                                <video width="100%" autoplay muted loop>
                                    <source src="video/iccv_submission/appearence1-1_compressed.mp4" type="video/mp4"> 
                                </video> 
                                <br>
                            </td>
                        <tr>
                        <tr>
                            <!-- First row of videos -->
                            <td width="100%" style="text-align:center;"> 
                                <video width="100%" autoplay muted loop> 
                                    <source src="video/iccv_submission/appearence2-1_compressed.mp4" type="video/mp4"> 
                                </video> 
                                <br>
                            </td>
                        <tr>
                        
                    </tbody>
                    </table>
                <br>
                <hr style="margin-top:0px">
            </div>
        </div>
        </div>

    </section>

    <section>
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">UniEdit + <a href="https://github.com/Vchitect/LaVie">LaVie</a> (Motion Editing)</h2>
                <p></p>
                <table style="table-layout: fixed;">
                <tbody>
                    <tr>
                        <!-- First row of videos -->
                        <td width="100%" style="text-align:center;">
                            <video width="100%" autoplay muted loop>
                                <source src="video/iccv_submission/motion1-1_compressed.mp4" type="video/mp4">
                            </video>
                            <br>
                        </td>
                    <tr>
                    
                </tbody>
                </table>
                <br>
                <hr style="margin-top:0px">
            </div>
        </div>
        </div>
    <br>
    </section>


    <section>
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3" id="sectionB" style="text-align:justify; word-wrap:break-word;">Section B: Analysis on the Proposed Components</h2>
                    <p class="title is-5" style="text-align:justify; word-wrap:break-word;">Difference between QK and V features in SA-S modules:</p>
                    <p><strong>+ 'Van Gogh style'</strong></p>
                    <div style="display: flex; justify-content: space-between;">
                        <div>
                            <video width="92.95%" autoplay muted loop> 
                                <source src="video/iccv_submission/explainv_source_compressed.mp4" type="video/mp4"> 
                            </video> 
                            <!-- <img src="./video/ablation/explain_v/source.gif" alt="Your browser does not support the image tag." style="width: 92.95%;" loop> -->
                            <p>(a) source video</p>
                        </div>
                        <div>
                            <video width="92.95%" autoplay muted loop> 
                                <source src="video/iccv_submission/explainv_stylization_wo_ours_compressed.mp4" type="video/mp4"> 
                            </video> 
                            <!-- <img src="./video/ablation/explain_v/stylization_wo_ours.gif" alt="Your browser does not support the image tag." style="width: 92.95%;" loop> -->
                            <p>(b) w/o feature replacement</p>
                        </div>

                    </div>
                    <div style="display: flex; justify-content: space-between;">

                        <div>
                            <video width="92.95%" autoplay muted loop> 
                                <source src="video/iccv_submission/explainv_stylization_qk_compressed.mp4" type="video/mp4"> 
                            </video> 
                            <!-- <img src="./video/ablation/explain_v/stylization_qk.gif" alt="Your browser does not support the image tag." style="width: 92.95%;" loop> -->
                            <p>(c) w/ query and key features replacement</p>
                        </div>
                        <div>
                            <video width="92.95%" autoplay muted loop> 
                                <source src="video/iccv_submission/explainv_stylization_v_compressed.mp4" type="video/mp4"> 
                            </video> 
                            <!-- <img src="./video/ablation/explain_v/stylization_v.gif" alt="Your browser does not support the image tag." style="width: 92.95%;" loop> -->
                            <p>(d) w/ value features replacement + query and key in (b)</p>
                        </div>
                    </div>
                    <p>Fig B.1.</p>
                    <br>
                    <p style="text-align:justify; word-wrap:break-word;"><strong>Observation:</strong> The query and key features (in SA-S modules) dictate the spatial structure of the generated video, while the value features tend to influence the texture, including details such as color tones.<br>To comprehend why we can have inhomogeneous QK and V and their differences, we visualized the results of swapping different features (QK or V) in SA-S modules during style transfer tasks on the source video in Fig. B.1. As can be seen, compared to Fig. B.1(b) with no feature replacement, replacing QK (Fig. B.1(c)) results in the edited video adopting the same spatial structure as the source video. Simultaneously, replacing V eradicates the style information in (Fig. B.1(b)), meaning the texture details from the source video are utilized to replace the style depicted by the target prompt.</p>


                    <br>
                    <hr style="margin-top:0px">
                    <p class="title is-5" style="text-align:justify; word-wrap:break-word;">Influence of Spatial Structure Control in Motion Editing:</p>
                    <p><strong>'playing guitar' --> 'eating an apple'</strong></p>
                    <div style="display: flex; justify-content: space-between;">
                        <div>
                            <video width="92.95%" autoplay muted loop> 
                                <source src="video/iccv_submission/wo_spatial_compressed.mp4" type="video/mp4"> 
                            </video> 
                            <!-- <img src="./video/iccv_submission/wo_spatial.gif" alt="Your browser does not support the image tag." style="width: 92.95%;" loop> -->
                            <p>(a). w/o Spatial Structure Control</p>
                        </div>

                    </div>
                    <div style="display: flex; justify-content: space-between;">

                        <div>
                            <video width="92.95%" autoplay muted loop> 
                                <source src="video/iccv_submission/w_spatial_compressed.mp4" type="video/mp4"> 
                            </video> 
                            <!-- <img src="./video/iccv_submission/w_spatial.gif" alt="Your browser does not support the image tag." style="width: 92.95%;" loop> -->
                            <p>(b). w/ Spatial Structure Control</p>
                        </div>
                    </div>
                    <p>Fig B.2.</p>
                    <br>
                    <p style="text-align:justify; word-wrap:break-word;">We explored the role of spatial control in motion editing. The proposed method synthesizes videos with larger modifications when removing the spatial control mechanism on both the motion-reference branch and the main editing branch. We visualized the results in Fig. B.2, from left to right are {reconstruction branch, main editing path, and motion reference branch} respectively. It can be observed that although the motion-reference branch can still generate the target motion without the control of spatial layout, the structure deviates significantly, for example, the raccoon assumes a different pose and location. We regard this as a suboptimal solution because, compared to the results presented in the paper, the results w/o spatial structure control modifies the object position of the source video, leading to a decrease in consistency between the edited result and the source video.
                    <br>
                    <br>
                    We add the quantitative results below:</p>
                <br>
                
                <table class="bordered-table">
                    <tr>
                        <td>Content Preservation</td>
                        <td>Motion Injection</td>
                        <td>Structure Control</td>
                        <td>Frame Similarity (&uarr;)</td>
                        <td>Textual Alignment (&uarr;)</td>
                        <td>Frame Consistency (&uarr;)</td>
                    </tr>
                    <tr>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                        <td>90.54</td>
                        <td>28.76</td>
                        <td>96.99</td>
                    </tr>
                    <tr>
                        <td>&check;</td>
                        <td></td>
                        <td></td>
                        <td>97.28</td>
                        <td>29.95</td>
                        <td>98.12</td>
                    </tr>
                    <tr>
                        <td></td>
                        <td>&check;</td>
                        <td>&check;</td>
                        <td>91.30</td>
                        <td>31.48</td>
                        <td>98.08</td>
                    </tr>
                    <tr>
                        <td>&check;</td>
                        <td>&check;</td>
                        <td></td>
                        <td>96.11</td>
                        <td>31.37</td>
                        <td>98.12</td>
                    </tr>
                    <tr>
                        <td>&check;</td>
                        <td>&check;</td>
                        <td>&check;</td>
                        <td>96.29</td>
                        <td>31.43</td>
                        <td>98.09</td>
                    </tr>
                </table>
                <hr style="margin-top:0px">

            </div>
        
        </div>
        </div>
        
    <br>
    </section>
    
    <section>
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3" id="sectionC" style="text-align:justify; word-wrap:break-word;">Section C: Impact of Hyper-parameter Selection</h2>

                <p class="title is-5" style="text-align:justify; word-wrap:break-word;">Appearance Editing (global):</p>
                <img src="./video/ablation/hyper/fig_hyper_ablation2.jpg" alt="Your browser does not support the image tag." loop>
                <p>Fig. C.1. (copied from Fig.8 in the main text)</p>
                <br>
                <p style="text-align:justify; word-wrap:break-word;">For appearance editing, it's observed that changing the blend layers (\(t_1\)) in Eq. 4 could effectively adjust the degree to which the edited image remains faithful to the original image. Take stylization in Fig. C.1 as an example, attention map injection on fewer (15) steps produces a stylized output that may not have the same structure as the input, and injection on all 50 steps could obtain videos with almost identical textures but less stylized. The user can adjust the blended layers and steps to realize their desired balancing between stylization and faithfully.</p>
                <hr style="margin-top:0px">
                    

                <br>
                <p style="text-align:justify; word-wrap:break-word;">In practice, we empirically found set these values to fixed values, i.e., \(t_0=50, L=10\) (same as MasaCtrl [1]) and \(t_1=25\) can achieve good results on most cases, and we further perform a quantitative study when applying different hyper-parameters:</p>
                
                    <table class="bordered-table">
                        <tr>
                            <td>Metric</td>
                            <td>Frame Similarity</td>
                            <td>Textual Alignment</td>
                            <td>Frame Consistency</td>
                        </tr>
                        <tr>
                            <td>\(t_0=20, L=10\)</td>
                            <td>94.33</td>
                            <td>31.57</td>
                            <td>98.09</td>
                        </tr>
                        <tr>
                            <td>\(t_0=50, L=10\)</td>
                            <td>96.29</td>
                            <td>31.84</td>
                            <td>98.12</td>
                        </tr>
                        <tr>
                            <td>\(t_0=50, L=8\)</td>
                            <td>96.76</td>
                            <td>31.25</td>
                            <td>98.11</td>
                        </tr>
                        <tr>
                            <td></td>
                            <td></td>
                            <td></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td>Metric</td>
                            <td>Frame Similarity</td>
                            <td>Textual Alignment</td>
                            <td>Frame Consistency</td>
                        </tr>
                        <!-- <tr>
                            <td>-------------------------</td>
                            <td>:--------------:</td>
                            <td>:---------------:</td>
                            <td>:---------------:</td>
                        </tr> -->
                        <tr>
                            <td>\(t_1=20\)</td>
                            <td>96.21</td>
                            <td>30.92</td>
                            <td>98.06</td>
                        </tr>
                        <tr>
                            <td>\(t_1=25\)</td>
                            <td>96.29</td>
                            <td>31.43</td>
                            <td>98.09</td>
                        </tr>
                        <tr>
                            <td>\(t_1=30\)</td>
                            <td>96.50</td>
                            <td>31.04</td>
                            <td>98.08</td>
                        </tr>
                    </table>
                <br>

            </div>
        
        </div>
        </div>
        
    <br>
    </section>

    <section>
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3" id="sectionD" style="text-align:justify; word-wrap:break-word;">Section D: Impact of Mask-Guided Coordination</h2>
                <p></p>
                    <p class="title is-5" style="text-align:justify; word-wrap:break-word;">Visualization of attention maps in CA-S modules:</p>
                    <img src="./video/ablation/mask/CA_attn_vis.jpg" alt="Your browser does not support the image tag." loop>

                    <p class="title is-5" style="text-align:justify; word-wrap:break-word;">Visualization of masks:</p>
                    <div style="display: flex; justify-content: space-between;">
                        <div>
                            <video width="92.95%" autoplay muted loop> 
                                <source src="video/iccv_submission/mask_source-1_compressed.mp4" type="video/mp4"> 
                            </video> 
                            <!-- <img src="./video/ablation/mask/source.gif" alt="Your browser does not support the image tag." style="width: 92.95%;" loop> -->
                            <p>Output Video<br></p>
                        </div>
                        <div>
                            <img src="./video/ablation/mask/ca_mask.png" alt="Your browser does not support the image tag." style="width: 92.95%;" loop>
                            <p>CA-S mask<br>(obtained by using threshold on the attention map of 'man')</p>
                        </div>
                        <div>
                            <img src="./video/ablation/mask/sam_mask.png" alt="Your browser does not support the image tag." style="width: 90%;" loop>
                            <p>SAM mask<br>(obtained by using point guided segmentation)</p>
                        </div>
                    </div>
                    
                <br>
                <table style="table-layout: fixed;">
                    <tbody>
                        <tr>
                            <p class="title is-5" style="text-align:justify; word-wrap:break-word;">Synthesis results when using UniEdit with or without mask:</p>
                            
                            <p><strong>'in NYC Times Square' --> 'in park, in winter'</strong></p>
                            <td width="50%" style="text-align:center;">
                                <video width="92.95%" autoplay muted loop> 
                                    <source src="video/iccv_submission/mask_without_uniedit-1_compressed.mp4" type="video/mp4"> 
                                </video> 
                                <!-- <img src="./video/ablation/mask/without_uniedit.gif" alt="Your browser does not support the image tag." loop> -->
    
                                <p><centered>Result without UniEdit</centered></p>
                                <br>
                            </td>
                            <td width="50%" style="text-align:center;">
                                <video width="92.95%" autoplay muted loop> 
                                    <source src="video/iccv_submission/mask_without_mask-1_compressed.mp4" type="video/mp4"> 
                                </video> 
                                <!-- <img src="./video/ablation/mask/without_mask.gif" alt="Your browser does not support the image tag." loop> -->
                                <p><centered>Result with UniEdit (no mask)</centered></p>
                                <br>
                            </td>
                        <tr>
                        
                        <tr>
                            <!-- First row of videos -->
                            <td width="50%" style="text-align:center;"> 
                                <video width="92.95%" autoplay muted loop> 
                                    <source src="video/iccv_submission/mask_withca_mask-1_compressed.mp4" type="video/mp4"> 
                                </video> 
                                <!-- <img src="./video/ablation/mask/with_ca_mask.gif" alt="Your browser does not support the image tag." loop> -->
                                <p><centered>Result with UniEdit (use attention mask in CA-S)</centered></p>
                                <br>
                            </td>
                            <td width="50%" style="text-align:center;"> 
                                <video width="92.95%" autoplay muted loop> 
                                    <source src="video/iccv_submission/mask_with_sam_mask-1_compressed.mp4" type="video/mp4"> 
                                </video> 
                                <!-- <img src="./video/ablation/mask/with_sam_mask.gif" alt="Your browser does not support the image tag." loop> -->
                                <p><centered>Result with UniEdit (use SAM segmentation mask)</centered></p>
                                <br>
                            </td>
                        <tr>
                        <tr>
                            <tr>
                                <td colspan="4""><strong>'cat' --> 'dog'</strong><br></td>
                            </tr>
                            
                            <td width="50%" style="text-align:center;">
                                <video width="100%" autoplay muted loop> 
                                    <source src="video/iccv_submission/mask_1-1_compressed.mp4" type="video/mp4"> 
                                </video> 
                                <!-- <img src="./video/ablation/mask/1.gif" alt="Your browser does not support the image tag." loop> -->
    
                                <p><centered>Result without UniEdit</centered></p>
                                <br>
                            </td>
                            <td width="50%" style="text-align:center;">
                                <video width="100%" autoplay muted loop> 
                                    <source src="video/iccv_submission/mask_2-1_compressed.mp4" type="video/mp4"> 
                                </video> 
                                <!-- <img src="./video/ablation/mask/2.gif" alt="Your browser does not support the image tag." loop> -->
                                <p><centered>Result with UniEdit (no mask)</centered></p>
                                <br>
                            </td>
                        <tr>
                        
                        <tr>
                            <!-- First row of videos -->
                            <td width="50%" style="text-align:center;"> 
                                <video width="100%" autoplay muted loop> 
                                    <source src="video/iccv_submission/mask_3-1_compressed.mp4" type="video/mp4"> 
                                </video> 
                                <!-- <img src="./video/ablation/mask/3.gif" alt="Your browser does not support the image tag." loop> -->
                                <p><centered>Result with UniEdit (use attention mask in CA-S)</centered></p>
                                <br>
                            </td>
                            <td width="50%" style="text-align:center;"> 
                                <video width="100%" autoplay muted loop> 
                                    <source src="video/iccv_submission/mask_4-1_compressed.mp4" type="video/mp4"> 
                                </video> 
                                <!-- <img src="./video/ablation/mask/4.gif" alt="Your browser does not support the image tag." loop> -->
                                <p><centered>Result with UniEdit (use SAM segmentation mask)</centered></p>
                                <br>
                            </td>

                        <tr>
                        
                    </tbody>
                </table>

                <p style="text-align:justify; word-wrap:break-word;">To investigate the impact of mask-guided coordination, we begin by visualizing masks obtained from 1) the attention map in CA-S modules; 2) the off-the-shelf segmentation model SAM [1], followed by presenting both qualitative and quantitative results of implementing UniEdit with or without mask-guided coordination.
                <br>
                <br>
                As verified by previous work [2], the attention maps in CA-S modules contain correspondence information between text and visual features. The underlying intuition is that the attention maps between each word and the spatial features at point (i, j) indicate 'how similar this token is to the spatial feature at this location'. We visualize the text-image cross attention map alongside the synthesized video in Section D. We observe spatial correspondences that align with the video output from the attention map. For instance, areas with higher values of the token 'man' and 'NYC' correspond to the foreground and background, respectively. We further employ a fixed threshold (0.4 in practice) to derive binary segmentation maps from the attention maps. For comparison, we also display the segmentation mask obtained by point prompt on SAM. It's observed that the cross-attention mask is generally accurate and could serve as a reliable proxy in practice when an external segmentor is not available.
                <br>
                <br>
                We examine the impact of mask-guided coordination through both qualitative and quantitative results across 4 settings: {w/o UniEdit, UniEdit w/o mask, UniEdit with mask from CA-S, UniEdit with mask from SAM}. Qualitatively, the implementation of UniEdit significantly enhances the consistency between the edited videos and the original video. The application of the mask-guided coordination technique further improves the consistency of unedited areas (e.g., color and texture). The quantitative results above align coherently with this analysis.
                <br>
                <br>
                [1] Kirillov, Alexander, et al. "Segment anything."
                <br>
                [2] Hertz, Amir, et al. "Prompt-to-Prompt Image Editing with Cross-Attention Control."
                </p>
                
                <hr style="margin-top:0px">

            </div>
        
        </div>
        </div>
        
    <br>
    </section>





    <section>
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3" id="sectionE" style="text-align:justify; word-wrap:break-word;">Section E: More Results and Visualization</h2>
                    <h2 class="title is-5" style="text-align:justify; word-wrap:break-word;">Visualization of the reconstruction branch and the motion-reference branch:</h2>
                    <p><strong>'playing guitar' --> 'waving'</strong></p>
                    <div style="display: flex; justify-content: space-between;">
                        <div>
                            <video width="92.95%" autoplay muted loop> 
                                <source src="video/iccv_submission/branch_vis_1-1_compressed.mp4" type="video/mp4"> 
                            </video> 
                            <!-- <img src="./video/ablation/branch_vis/1.gif" alt="Your browser does not support the image tag." style="width: 92.95%;" loop> -->
                            <p></p>
                        </div>
                    </div>
                    <p><strong>'walking' --> 'lying'</strong></p>
                    <div style="display: flex; justify-content: space-between;">
                        <div>
                            <video width="92.95%" autoplay muted loop> 
                                <source src="video/iccv_submission/branch_vis_2-1_compressed.mp4" type="video/mp4"> 
                            </video> 
                            <!-- <img src="./video/ablation/branch_vis/2.gif" alt="Your browser does not support the image tag." style="width: 92.95%;" loop> -->
                            <p></p>
                        </div>
                    </div>
                    <p>Fig. E.1.</p>
                    <br>
                    <p style="text-align:justify; word-wrap:break-word;">The output of each branch is visualized in section E, Fig. E.1, where it is observed that the motion branch (right) generate video with the target motion, and effectively transfer it to the main path (middle); meanwhile, the main path inherit the content from the reconstruction branch (left), thus enhance the consistency of unedited parts.</p>
                    <hr style="margin-top:0px">

                    <h2 class="title is-5" style="text-align:justify; word-wrap:break-word;">Qualitative results on the reconstruction branch:</h2>
                        <div style="display: flex; justify-content: space-between;">
                            <div>
                                <video width="92.95%" autoplay muted loop> 
                                    <source src="video/iccv_submission/recons_input_lotus-1_compressed.mp4" type="video/mp4"> 
                                </video> 
                                <!-- <img src="./video/ablation/recons/input_lotus.gif" alt="Your browser does not support the image tag." style="width: 92.95%;" loop> -->
                                <p>Source Video</p>
                            </div>
                            <div>
                                <video width="92.95%" autoplay muted loop> 
                                    <source src="video/iccv_submission/recons_lotus_sd-1_compressed.mp4" type="video/mp4"> 
                                </video> 
                                <!-- <img src="./video/ablation/recons/sd_scheduler_lotus.gif" alt="Your browser does not support the image tag." style="width: 92.95%;" loop> -->
                                <p>Reconstruction Branch Output<br></p>
                            </div>
                            <div>
                                <video width="92.95%" autoplay muted loop> 
                                    <source src="video/iccv_submission/recons_lotus_nti-1_compressed.mp4" type="video/mp4"> 
                                </video> 
                                <!-- <img src="./video/ablation/recons/nti_lotus.gif" alt="Your browser does not support the image tag." style="width: 92.95%;" loop> -->
                                <p>Reconstruction Branch Output<br>(w/ null-text inversion)</p>
                            </div>
                        </div>
                        <div style="display: flex; justify-content: space-between;">
                            <div>
                                <video width="92.95%" autoplay muted loop> 
                                    <source src="video/iccv_submission/recons_input_basketball-1_compressed.mp4" type="video/mp4"> 
                                </video> 
                                <!-- <img src="./video/ablation/recons/input_basketball.gif" alt="Your browser does not support the image tag." style="width: 92.95%;" loop> -->
                                <p>Source Video</p>
                            </div>
                            <div>
                                <video width="92.95%" autoplay muted loop> 
                                    <source src="video/iccv_submission/recons_basketball_sd-1_compressed.mp4" type="video/mp4"> 
                                </video> 
                                <!-- <img src="./video/ablation/recons/sd_scheduler_basketball.gif" alt="Your browser does not support the image tag." style="width: 92.95%;" loop> -->
                                <p>Reconstruction Branch Output<br></p>
                            </div>
                            <div>
                                <video width="92.95%" autoplay muted loop> 
                                    <source src="video/iccv_submission/recons_basketball_nti-1_compressed.mp4" type="video/mp4"> 
                                </video> 
                                <!-- <img src="./video/ablation/recons/nti_basketball.gif" alt="Your browser does not support the image tag." style="width: 92.95%;" loop> -->
                                <p>Reconstruction Branch Output<br>(w/ null-text inversion)</p>
                            </div>
                        </div>
                        <p>Fig. E.2.</p>
                        <table style="border-collapse: collapse; width: 100%;">
                            <tr>
                                <td style="border: 1px solid black;">Metrics</td>
                                <td style="border: 1px solid black;">FID (&darr;)</td>
                                <td style="border: 1px solid black;">LPIPS (&darr;)</td>
                                <td style="border: 1px solid black;">PSNR (&uarr;)</td>
                            </tr>
                            <tr>
                                <td style="border: 1px solid black;">DDIM</td>
                                <td style="border: 1px solid black;">21.30</td>
                                <td style="border: 1px solid black;">0.140</td>
                                <td style="border: 1px solid black;">34.26</td>
                            </tr>
                            <tr>
                                <td style="border: 1px solid black;">DDIM + Null-text inversion [4]</td>
                                <td style="border: 1px solid black;">17.81</td>
                                <td style="border: 1px solid black;">0.158</td>
                                <td style="border: 1px solid black;">33.75</td>
                            </tr>
                        </table>

                        <p style="text-align:justify; word-wrap:break-word;">As seen, the reconstruction branch is capable of faithfully reconstructing the source video. Therefore, the reconstruction branch retains the content of the source video and can be leveraged for content preservation during the editing process.</p>
                    <br>
                    <hr style="margin-top:0px">
                    <p class="title is-5" style="text-align:justify; word-wrap:break-word;">Visualization of foreground mask extracted by \(U^2\)-Net:</p>
                    <div style="display: flex; justify-content: space-between;">
                        <div>
                            <img src="./video/ablation/salient/sos1_source.png" alt="Your browser does not support the image tag." style="width: 92.95%;" loop>
                            <p></p>
                        </div>

                        <div>
                            <img src="./video/ablation/salient/sos1.png" alt="Your browser does not support the image tag." style="width: 92.95%;" loop>
                            <p></p>
                        </div>
                    </div>
                    <p>Fig. E.3.</p>
                <hr style="margin-top:0px">

            </div>
        
        </div>
        </div>
        
    <br>
    </section>

    
    <section>
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3" id="sectionF" style="text-align:justify; word-wrap:break-word;">Section F: Failure Cases Visualization</h2>
                    <h2 class="title is-5" style="text-align:justify; word-wrap:break-word;">Edit multiple elements simultaneously:</h2>
                    <div style="display: flex; justify-content: space-between;">
                        <div>
                            <video width="92.95%" autoplay muted loop> 
                                <source src="video/iccv_submission/failure_1-1_compressed.mp4" type="video/mp4"> 
                            </video> 
                            <!-- <img src="./video/ablation/failure/1.gif" alt="Your browser does not support the image tag." style="width: 60%;" loop> -->
                            <p>cat --> dog, + Van Gogh style</p>
                        </div>
                    </div>
                    <div style="display: flex; justify-content: space-between;">
                        <div>
                            <video width="92.95%" autoplay muted loop> 
                                <source src="video/iccv_submission/failure_2-1_compressed.mp4" type="video/mp4"> 
                            </video> 
                            <!-- <img src="./video/ablation/failure/2.gif" alt="Your browser does not support the image tag." style="width: 60%;" loop> -->
                            <p>raccoon --> panda, play violin --> waving</p>
                        </div>
                    </div>
                    <div style="display: flex; justify-content: space-between;">

                        <div>
                            <video width="92.95%" autoplay muted loop> 
                                <source src="video/iccv_submission/failure_3-1_compressed.mp4" type="video/mp4"> 
                            </video> 
                            <!-- <img src="./video/ablation/failure/4.gif" alt="Your browser does not support the image tag." style="width: 60%;" loop> -->
                            <p>raccoon --> kangaroo, play violin --> play guitar<br>(the model do not learn the correct posture for playing the violin, and whether or not our method is used, the model could not generate the posture of "violin on the shoulder")</p>
                        </div>
                    </div>
                    <h2 class="title is-5" style="text-align:justify; word-wrap:break-word;">Complex scene editing:</h2>
                    <div style="display: flex; justify-content: space-between;">
                        <div>
                            <video width="92.95%" autoplay muted loop> 
                                <source src="video/iccv_submission/failure_4-1_compressed.mp4" type="video/mp4"> 
                            </video> 
                            <!-- <img src="./video/ablation/failure/3.gif" alt="Your browser does not support the image tag." style="width: 60%;" loop> -->
                            <p>a shark on the left and several goldfish swim in a tank</p>
                        </div>
                    </div>
                <br>
                <p style="text-align:justify; word-wrap:break-word;">We exhibit failure cases in section F. Rows 1-3 showcase when editing multiple elements  simultaneously, and we observe a relatively large inconsistency with the source video. A naive solution is that perform editing with UniEdit multiple times. Row 4 visualizes the results when editing video with complex scenes, and the model sometimes could not understand the semantics in the target prompt, resulting in incorrect editing. This may be caused by the base model's limited text understanding power, as discussed in [1]. It could be alleviated by leveraging the reasoning power of MLLM [1], or adapting approaches in complex scenario editing [2].
                <br>
                <br>
                [1] Huang, Yuzhou, et al. "SmartEdit: Exploring Complex Instruction-based Image Editing with Multimodal Large Language Models."
                <br>
                [2] Mao, Qi, et al. "MAG-Edit: Localized Image Editing in Complex Scenarios via Mask-Based Attention-Adjusted Guidance."</p>
                <br>
                <hr style="margin-top:0px">

            </div>
        
        </div>
        </div>
        
    <br>
    </section>

    <section>
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3" id="sectionG" style="text-align:justify; word-wrap:break-word;">Section G: Comparison with State-of-the-Art Methods</h2>
                <p></p>
                <table style="table-layout: fixed;">
                <tbody>
                    <tr>
                        <!-- First row of videos -->
                        <td width="100%" style="text-align:center;">
                            <video width="100%" autoplay muted loop>
                                <source src="video/iccv_submission/compare_video_compressed.mp4" type="video/mp4">
                            </video>
                            <br>
                        </td>
                    <tr>
                    
                </tbody>
                </table>
                <br>
                <hr style="margin-top:0px">
            </div>
        </div>
        </div>
    <br>
    </section>

</body>

</html>
